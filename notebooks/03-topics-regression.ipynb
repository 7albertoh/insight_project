{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import random\n",
    "import numpy as np\n",
    "import math\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "random.seed(123)\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>book_title</th>\n",
       "      <th>author_num_unique_books</th>\n",
       "      <th>book_reviews</th>\n",
       "      <th>genres_str</th>\n",
       "      <th>topic 0</th>\n",
       "      <th>topic 1</th>\n",
       "      <th>topic 2</th>\n",
       "      <th>topic 3</th>\n",
       "      <th>topic 4</th>\n",
       "      <th>...</th>\n",
       "      <th>topic 6</th>\n",
       "      <th>topic 7</th>\n",
       "      <th>topic 8</th>\n",
       "      <th>topic 9</th>\n",
       "      <th>topic 10</th>\n",
       "      <th>topic 11</th>\n",
       "      <th>topic 12</th>\n",
       "      <th>topic 13</th>\n",
       "      <th>topic 14</th>\n",
       "      <th>reviews_per_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.20</td>\n",
       "      <td>The Gifts of Imperfection</td>\n",
       "      <td>53.0</td>\n",
       "      <td>Ive read more than my fair share of self-help ...</td>\n",
       "      <td>audiobook health inspirational mental-health n...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55.458333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.27</td>\n",
       "      <td>Daring Greatly</td>\n",
       "      <td>53.0</td>\n",
       "      <td>This book came highly recommended by seemingly...</td>\n",
       "      <td>audiobook business leadership non-fiction pare...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>91.406250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.82</td>\n",
       "      <td>Who Moved My Cheese?</td>\n",
       "      <td>69.0</td>\n",
       "      <td>Who Moved My Cheese?  Spencer Johnson Who Move...</td>\n",
       "      <td>buisness business inspirational leadership man...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.746212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.68</td>\n",
       "      <td>The Secret (The Secret, #1)</td>\n",
       "      <td>55.0</td>\n",
       "      <td>I wasnt interested in reading this book. I tho...</td>\n",
       "      <td>audiobook business inspirational new-age non-f...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73.982143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.62</td>\n",
       "      <td>The Happiness Project</td>\n",
       "      <td>21.0</td>\n",
       "      <td>I have no idea how to properly convey how I fe...</td>\n",
       "      <td>adult audiobook biography biography-memoir ins...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>95.848485</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   avg_rating                   book_title  author_num_unique_books  \\\n",
       "0        4.20    The Gifts of Imperfection                     53.0   \n",
       "1        4.27               Daring Greatly                     53.0   \n",
       "2        3.82         Who Moved My Cheese?                     69.0   \n",
       "3        3.68  The Secret (The Secret, #1)                     55.0   \n",
       "4        3.62        The Happiness Project                     21.0   \n",
       "\n",
       "                                        book_reviews  \\\n",
       "0  Ive read more than my fair share of self-help ...   \n",
       "1  This book came highly recommended by seemingly...   \n",
       "2  Who Moved My Cheese?  Spencer Johnson Who Move...   \n",
       "3  I wasnt interested in reading this book. I tho...   \n",
       "4  I have no idea how to properly convey how I fe...   \n",
       "\n",
       "                                          genres_str  topic 0  topic 1  \\\n",
       "0  audiobook health inspirational mental-health n...      0.0      0.0   \n",
       "1  audiobook business leadership non-fiction pare...      0.0      0.0   \n",
       "2  buisness business inspirational leadership man...      0.0      0.0   \n",
       "3  audiobook business inspirational new-age non-f...      0.0      0.0   \n",
       "4  adult audiobook biography biography-memoir ins...      0.0      0.0   \n",
       "\n",
       "   topic 2  topic 3  topic 4  ...  topic 6  topic 7  topic 8  topic 9  \\\n",
       "0      0.0      1.0      0.0  ...      0.0      0.0      1.0      0.0   \n",
       "1      0.0      1.0      0.0  ...      0.0      0.0      0.0      0.0   \n",
       "2      0.0      0.0      0.0  ...      1.0      0.0      0.0      0.0   \n",
       "3      0.0      0.0      0.0  ...      0.0      0.0      0.0      0.0   \n",
       "4      0.0      0.0      0.0  ...      0.0      0.0      1.0      0.0   \n",
       "\n",
       "   topic 10  topic 11  topic 12  topic 13  topic 14  reviews_per_month  \n",
       "0       0.0       0.0       0.0       0.0       0.0          55.458333  \n",
       "1       0.0       0.0       0.0       0.0       0.0          91.406250  \n",
       "2       0.0       0.0       1.0       1.0       0.0          45.746212  \n",
       "3       0.0       0.0       0.0       0.0       0.0          73.982143  \n",
       "4       0.0       0.0       1.0       0.0       0.0          95.848485  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv('../data/books_25_pages_clean0_description_genres.csv',skipinitialspace=True)\n",
    "df1 = df1.rename(columns = lambda x: x.strip())\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426\n"
     ]
    }
   ],
   "source": [
    "# create training and testing dataframes\n",
    "num_half = int(len(df1.index)/2)\n",
    "print(num_half)\n",
    "df_train = df1.sample(frac=1).head(n=num_half)\n",
    "df_validate = df1.sample(frac=1).tail(n=len(df1.index)-num_half)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = [] #'author_num_unique_books','avg_rating'\n",
    "for coli in df_train.columns:\n",
    "    if \"topic\" in coli: features.append(coli)\n",
    "\n",
    "len(features)\n",
    "# for i in range(0,len(list(df1.columns))):\n",
    "#     print(i,list(df1.columns)[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "sns.heatmap(df_train[features].corr(), annot=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # build linear regression model\n",
    "X_train = df_train[features]\n",
    "y_train = df_train['reviews_per_month']\n",
    "X_validate = df_validate[features]\n",
    "y_validate = df_validate['reviews_per_month']\n",
    "# regr = LinearRegression()\n",
    "# regr.fit(X_train, y_train)\n",
    "# y_pred_validate = regr.predict(X_validate)\n",
    "# regr.score(X_train, y_train)\n",
    "# # print('rmse validation',math.sqrt(mean_squared_error(y_validate, y_pred_validate)))\n",
    "# # print('rsq validation',r2_score(y_validate, y_pred_validate))\n",
    "# # print('rmse training',math.sqrt(mean_squared_error(y_train, regr.predict(X_train))))\n",
    "# # print('rsq training',r2_score(y_train, regr.predict(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.scatter(y_validate,y_pred_validate,  color='black')\n",
    "# # plt.plot(X_validate, y_pred_validate, color='blue', linewidth=3)\n",
    "# plt.plot(sorted(y_validate,key=float), sorted(y_validate,key=float),'--', linewidth=1,color='red')\n",
    "# # plt.xticks(())\n",
    "# # plt.yticks(())\n",
    "\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regr.intercept_\n",
    "# regr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>    <td>reviews_per_month</td> <th>  R-squared (uncentered):</th>      <td>   0.311</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>        <th>  Adj. R-squared (uncentered):</th> <td>   0.285</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>   <th>  F-statistic:       </th>          <td>   12.35</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 01 Oct 2020</td>  <th>  Prob (F-statistic):</th>          <td>2.20e-25</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>21:44:20</td>      <th>  Log-Likelihood:    </th>          <td> -1842.4</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   426</td>       <th>  AIC:               </th>          <td>   3715.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   411</td>       <th>  BIC:               </th>          <td>   3776.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    15</td>       <th>                     </th>              <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>     <th>                     </th>              <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>        <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>topic 0</th>  <td>    8.6348</td> <td>    2.247</td> <td>    3.842</td> <td> 0.000</td> <td>    4.217</td> <td>   13.052</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>topic 1</th>  <td>    4.2724</td> <td>    2.620</td> <td>    1.630</td> <td> 0.104</td> <td>   -0.879</td> <td>    9.424</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>topic 2</th>  <td>    9.6036</td> <td>    2.882</td> <td>    3.332</td> <td> 0.001</td> <td>    3.938</td> <td>   15.270</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>topic 3</th>  <td>    2.2822</td> <td>    3.009</td> <td>    0.759</td> <td> 0.449</td> <td>   -3.632</td> <td>    8.197</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>topic 4</th>  <td>    4.4376</td> <td>    2.938</td> <td>    1.510</td> <td> 0.132</td> <td>   -1.339</td> <td>   10.214</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>topic 5</th>  <td>    7.8651</td> <td>    2.396</td> <td>    3.283</td> <td> 0.001</td> <td>    3.156</td> <td>   12.574</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>topic 6</th>  <td>   -1.2006</td> <td>    2.579</td> <td>   -0.465</td> <td> 0.642</td> <td>   -6.271</td> <td>    3.870</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>topic 7</th>  <td>    4.8449</td> <td>    2.139</td> <td>    2.265</td> <td> 0.024</td> <td>    0.640</td> <td>    9.050</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>topic 8</th>  <td>    4.3694</td> <td>    2.294</td> <td>    1.904</td> <td> 0.058</td> <td>   -0.141</td> <td>    8.880</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>topic 9</th>  <td>    7.0929</td> <td>    2.891</td> <td>    2.453</td> <td> 0.015</td> <td>    1.410</td> <td>   12.776</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>topic 10</th> <td>    4.7326</td> <td>    3.768</td> <td>    1.256</td> <td> 0.210</td> <td>   -2.675</td> <td>   12.140</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>topic 11</th> <td>    4.2744</td> <td>    3.328</td> <td>    1.284</td> <td> 0.200</td> <td>   -2.268</td> <td>   10.817</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>topic 12</th> <td>    9.4783</td> <td>    2.175</td> <td>    4.358</td> <td> 0.000</td> <td>    5.203</td> <td>   13.754</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>topic 13</th> <td>    7.2667</td> <td>    2.883</td> <td>    2.521</td> <td> 0.012</td> <td>    1.600</td> <td>   12.933</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>topic 14</th> <td>    4.9689</td> <td>    3.584</td> <td>    1.386</td> <td> 0.166</td> <td>   -2.077</td> <td>   12.015</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>194.505</td> <th>  Durbin-Watson:     </th> <td>   1.938</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 737.846</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 2.109</td>  <th>  Prob(JB):          </th> <td>6.01e-161</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 7.876</td>  <th>  Cond. No.          </th> <td>    2.62</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] RÂ² is computed without centering (uncentered) since the model does not contain a constant.<br/>[2] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                                 OLS Regression Results                                \n",
       "=======================================================================================\n",
       "Dep. Variable:      reviews_per_month   R-squared (uncentered):                   0.311\n",
       "Model:                            OLS   Adj. R-squared (uncentered):              0.285\n",
       "Method:                 Least Squares   F-statistic:                              12.35\n",
       "Date:                Thu, 01 Oct 2020   Prob (F-statistic):                    2.20e-25\n",
       "Time:                        21:44:20   Log-Likelihood:                         -1842.4\n",
       "No. Observations:                 426   AIC:                                      3715.\n",
       "Df Residuals:                     411   BIC:                                      3776.\n",
       "Df Model:                          15                                                  \n",
       "Covariance Type:            nonrobust                                                  \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "topic 0        8.6348      2.247      3.842      0.000       4.217      13.052\n",
       "topic 1        4.2724      2.620      1.630      0.104      -0.879       9.424\n",
       "topic 2        9.6036      2.882      3.332      0.001       3.938      15.270\n",
       "topic 3        2.2822      3.009      0.759      0.449      -3.632       8.197\n",
       "topic 4        4.4376      2.938      1.510      0.132      -1.339      10.214\n",
       "topic 5        7.8651      2.396      3.283      0.001       3.156      12.574\n",
       "topic 6       -1.2006      2.579     -0.465      0.642      -6.271       3.870\n",
       "topic 7        4.8449      2.139      2.265      0.024       0.640       9.050\n",
       "topic 8        4.3694      2.294      1.904      0.058      -0.141       8.880\n",
       "topic 9        7.0929      2.891      2.453      0.015       1.410      12.776\n",
       "topic 10       4.7326      3.768      1.256      0.210      -2.675      12.140\n",
       "topic 11       4.2744      3.328      1.284      0.200      -2.268      10.817\n",
       "topic 12       9.4783      2.175      4.358      0.000       5.203      13.754\n",
       "topic 13       7.2667      2.883      2.521      0.012       1.600      12.933\n",
       "topic 14       4.9689      3.584      1.386      0.166      -2.077      12.015\n",
       "==============================================================================\n",
       "Omnibus:                      194.505   Durbin-Watson:                   1.938\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              737.846\n",
       "Skew:                           2.109   Prob(JB):                    6.01e-161\n",
       "Kurtosis:                       7.876   Cond. No.                         2.62\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] RÂ² is computed without centering (uncentered) since the model does not contain a constant.\n",
       "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ols = sm.OLS(y_train,X_train)\n",
    "ols_result = ols.fit()\n",
    "ols_result.save(\"../data/ols.pickle\")\n",
    "\n",
    "predict = ols_result.predict(X_train)\n",
    "ols_result.summary()\n",
    "\n",
    "# from statsmodels.graphics.regressionplots import plot_leverage_resid2\n",
    "# fig, ax = plt.subplots(figsize=(8,6))\n",
    "# fig = plot_leverage_resid2(ols_result, ax = ax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>coefficient</th>\n",
       "      <th>p-val</th>\n",
       "      <th>conf_int_low</th>\n",
       "      <th>conf_int_high</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>9.478323</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>5.202784</td>\n",
       "      <td>13.753863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>8.634836</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>4.217267</td>\n",
       "      <td>13.052406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>9.603615</td>\n",
       "      <td>0.000941</td>\n",
       "      <td>3.937642</td>\n",
       "      <td>15.269588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>7.865123</td>\n",
       "      <td>0.001114</td>\n",
       "      <td>3.156088</td>\n",
       "      <td>12.574159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>7.266651</td>\n",
       "      <td>0.012084</td>\n",
       "      <td>1.600194</td>\n",
       "      <td>12.933108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>7.092919</td>\n",
       "      <td>0.014570</td>\n",
       "      <td>1.409586</td>\n",
       "      <td>12.776252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>4.844886</td>\n",
       "      <td>0.024035</td>\n",
       "      <td>0.640038</td>\n",
       "      <td>9.049734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>4.369447</td>\n",
       "      <td>0.057556</td>\n",
       "      <td>-0.140768</td>\n",
       "      <td>8.879662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4.272432</td>\n",
       "      <td>0.103782</td>\n",
       "      <td>-0.878772</td>\n",
       "      <td>9.423636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4.437552</td>\n",
       "      <td>0.131768</td>\n",
       "      <td>-1.338704</td>\n",
       "      <td>10.213807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>4.968919</td>\n",
       "      <td>0.166430</td>\n",
       "      <td>-2.077314</td>\n",
       "      <td>12.015153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>4.274387</td>\n",
       "      <td>0.199766</td>\n",
       "      <td>-2.268084</td>\n",
       "      <td>10.816857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>4.732553</td>\n",
       "      <td>0.209862</td>\n",
       "      <td>-2.674839</td>\n",
       "      <td>12.139944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2.282184</td>\n",
       "      <td>0.448573</td>\n",
       "      <td>-3.632224</td>\n",
       "      <td>8.196593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>-1.200618</td>\n",
       "      <td>0.641851</td>\n",
       "      <td>-6.271155</td>\n",
       "      <td>3.869919</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    topic  coefficient     p-val  conf_int_low  conf_int_high\n",
       "12     12     9.478323  0.000017      5.202784      13.753863\n",
       "0       0     8.634836  0.000141      4.217267      13.052406\n",
       "2       2     9.603615  0.000941      3.937642      15.269588\n",
       "5       5     7.865123  0.001114      3.156088      12.574159\n",
       "13     13     7.266651  0.012084      1.600194      12.933108\n",
       "9       9     7.092919  0.014570      1.409586      12.776252\n",
       "7       7     4.844886  0.024035      0.640038       9.049734\n",
       "8       8     4.369447  0.057556     -0.140768       8.879662\n",
       "1       1     4.272432  0.103782     -0.878772       9.423636\n",
       "4       4     4.437552  0.131768     -1.338704      10.213807\n",
       "14     14     4.968919  0.166430     -2.077314      12.015153\n",
       "11     11     4.274387  0.199766     -2.268084      10.816857\n",
       "10     10     4.732553  0.209862     -2.674839      12.139944\n",
       "3       3     2.282184  0.448573     -3.632224       8.196593\n",
       "6       6    -1.200618  0.641851     -6.271155       3.869919"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_coeff = pd.DataFrame() #.reset_index()\n",
    "df_coeff['coefficient'] = ols_result.params\n",
    "df_coeff['p-val'] = ols_result.pvalues\n",
    "df_coeff['conf_int_low'] = ols_result.conf_int()[0].values\n",
    "df_coeff['conf_int_high'] = ols_result.conf_int()[1].values\n",
    "df_coeff = df_coeff.reset_index()\n",
    "df_coeff['index'] = [i for i in range(0,len(df_coeff.index))]\n",
    "df_coeff = df_coeff.rename(columns={'index':'topic'})\n",
    "df_coeff.sort_values(by=['p-val'],ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots()\n",
    "# fig = sm.graphics.plot_fit(ols_result, 0, ax=ax)\n",
    "# ax.set_ylabel(\"Murder Rate\")\n",
    "# ax.set_xlabel(\"Poverty Level\")\n",
    "# ax.set_title(\"Linear Regression\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VIF Factor</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.1</td>\n",
       "      <td>topic 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.1</td>\n",
       "      <td>topic 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.1</td>\n",
       "      <td>topic 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.1</td>\n",
       "      <td>topic 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.1</td>\n",
       "      <td>topic 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.1</td>\n",
       "      <td>topic 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.1</td>\n",
       "      <td>topic 6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.1</td>\n",
       "      <td>topic 7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.2</td>\n",
       "      <td>topic 8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.1</td>\n",
       "      <td>topic 9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.1</td>\n",
       "      <td>topic 10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.1</td>\n",
       "      <td>topic 11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.1</td>\n",
       "      <td>topic 12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.1</td>\n",
       "      <td>topic 13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.1</td>\n",
       "      <td>topic 14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    VIF Factor  features\n",
       "0          1.1   topic 0\n",
       "1          1.1   topic 1\n",
       "2          1.1   topic 2\n",
       "3          1.1   topic 3\n",
       "4          1.1   topic 4\n",
       "5          1.1   topic 5\n",
       "6          1.1   topic 6\n",
       "7          1.1   topic 7\n",
       "8          1.2   topic 8\n",
       "9          1.1   topic 9\n",
       "10         1.1  topic 10\n",
       "11         1.1  topic 11\n",
       "12         1.1  topic 12\n",
       "13         1.1  topic 13\n",
       "14         1.1  topic 14"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vif = pd.DataFrame()\n",
    "vif[\"VIF Factor\"] = [variance_inflation_factor(X_train.values, i) for i in range(X_train.shape[1])]\n",
    "vif[\"features\"] = X_train.columns\n",
    "vif.round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ynewpred =  ols_result.predict(X_validate) # predict out of sample\n",
    "fig, ax = plt.subplots()\n",
    "# ax.plot(x1, y, 'o', label=\"Data\")\n",
    "# ax.plot(x1, y_true, 'b-', label=\"True\")\n",
    "\n",
    "\n",
    "plt.scatter(ols_result.predict(X_train), ynewpred,  color='black')\n",
    "# plt.plot(X_validate, y_pred_validate, color='blue', linewidth=3)\n",
    "plt.plot(sorted(y_validate,key=float), sorted(y_validate,key=float),'--', linewidth=1,color='red')\n",
    "# plt.xticks(())\n",
    "# plt.yticks(())\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\valer\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from num2words import num2words\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "def convert_lower_case(data):\n",
    "    return np.char.lower(data)\n",
    "def remove_stop_words(data):\n",
    "    stop_words = stopwords.words('english')\n",
    "    words = word_tokenize(str(data))\n",
    "    new_text = \"\"\n",
    "    for w in words:\n",
    "        if w not in stop_words and len(w) > 1:\n",
    "            new_text = new_text + \" \" + w\n",
    "    return new_text\n",
    "def remove_punctuation(data):\n",
    "    symbols = \"!\\\"#$%&()*+-./:;<=>?@[\\]^_`{|}~\\n\"\n",
    "    for i in range(len(symbols)):\n",
    "        data = np.char.replace(data, symbols[i], ' ')\n",
    "        data = np.char.replace(data, \"  \", \" \")\n",
    "    data = np.char.replace(data, ',', '')\n",
    "    return data\n",
    "def remove_apostrophe(data):\n",
    "    return np.char.replace(data, \"'\", \"\")\n",
    "def stemming(data):\n",
    "    stemmer= PorterStemmer()\n",
    "    \n",
    "    tokens = word_tokenize(str(data))\n",
    "    new_text = \"\"\n",
    "    for w in tokens:\n",
    "        new_text = new_text + \" \" + stemmer.stem(w)\n",
    "    return new_text\n",
    "def convert_numbers(data):\n",
    "    tokens = word_tokenize(str(data))\n",
    "    new_text = \"\"\n",
    "    for w in tokens:\n",
    "        try:\n",
    "            w = num2words(int(w))\n",
    "        except:\n",
    "            a = 0\n",
    "        new_text = new_text + \" \" + w\n",
    "    new_text = np.char.replace(new_text, \"-\", \" \")\n",
    "    return new_text\n",
    "def remove_obvious(data):\n",
    "    return_data = str(data).replace(\"book\",\"\").replace(\"self\",\"\").replace(\"help\",\"\").replace(\"author\",\"\").replace(\"peopl\",\"person\").replace(\"bestsel\",\"\").replace(\"reader\",\"\")\n",
    "    return return_data \n",
    "\n",
    "def preprocess(data):\n",
    "    data = convert_lower_case(data)\n",
    "    data = remove_punctuation(data) #remove comma seperately\n",
    "    data = remove_apostrophe(data)\n",
    "    data = remove_stop_words(data)\n",
    "    data = convert_numbers(data)\n",
    "    data = stemming(data)\n",
    "    data = remove_punctuation(data)\n",
    "    data = convert_numbers(data)\n",
    "    data = stemming(data) #needed again as we need to stem the words\n",
    "    data = remove_punctuation(data) #needed again as num2word is giving few hypens and commas fourty-one\n",
    "    data = remove_stop_words(data) #needed again as num2word is giving stop words 101 - one hundred and one\n",
    "    data = remove_obvious(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename_model = '../data/topic_model_tfidf_nmf.pickle'\n",
    "nmf_model = pickle.load(open(filename_model, 'rb'))\n",
    "filename_model = '../data/topic_model_tfidf.pickle'\n",
    "tfidf_model = pickle.load(open(filename_model, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>coefficient</th>\n",
       "      <th>p-val</th>\n",
       "      <th>conf_int_low</th>\n",
       "      <th>conf_int_high</th>\n",
       "      <th>top_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>9.478323</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>5.202784</td>\n",
       "      <td>13.753863</td>\n",
       "      <td>success business job create</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>8.634836</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>4.217267</td>\n",
       "      <td>13.052406</td>\n",
       "      <td>human problem present reason fact effect happen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>9.603615</td>\n",
       "      <td>0.000941</td>\n",
       "      <td>3.937642</td>\n",
       "      <td>15.269588</td>\n",
       "      <td>women</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>7.865123</td>\n",
       "      <td>0.001114</td>\n",
       "      <td>3.156088</td>\n",
       "      <td>12.574159</td>\n",
       "      <td>happy positive reason present happen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>7.266651</td>\n",
       "      <td>0.012084</td>\n",
       "      <td>1.600194</td>\n",
       "      <td>12.933108</td>\n",
       "      <td>goal step success create</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>7.092919</td>\n",
       "      <td>0.014570</td>\n",
       "      <td>1.409586</td>\n",
       "      <td>12.776252</td>\n",
       "      <td>emotion step effect positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>4.844886</td>\n",
       "      <td>0.024035</td>\n",
       "      <td>0.640038</td>\n",
       "      <td>9.049734</td>\n",
       "      <td>advice step job inform problem inspire business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>4.369447</td>\n",
       "      <td>0.057556</td>\n",
       "      <td>-0.140768</td>\n",
       "      <td>8.879662</td>\n",
       "      <td>story inspire happen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4.272432</td>\n",
       "      <td>0.103782</td>\n",
       "      <td>-0.878772</td>\n",
       "      <td>9.423636</td>\n",
       "      <td>relationship problem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4.437552</td>\n",
       "      <td>0.131768</td>\n",
       "      <td>-1.338704</td>\n",
       "      <td>10.213807</td>\n",
       "      <td>question ask job create inform business happen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>4.968919</td>\n",
       "      <td>0.166430</td>\n",
       "      <td>-2.077314</td>\n",
       "      <td>12.015153</td>\n",
       "      <td>listen present ask advice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>4.274387</td>\n",
       "      <td>0.199766</td>\n",
       "      <td>-2.268084</td>\n",
       "      <td>10.816857</td>\n",
       "      <td>habit step effect problem inform</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>4.732553</td>\n",
       "      <td>0.209862</td>\n",
       "      <td>-2.674839</td>\n",
       "      <td>12.139944</td>\n",
       "      <td>brain inform</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2.282184</td>\n",
       "      <td>0.448573</td>\n",
       "      <td>-3.632224</td>\n",
       "      <td>8.196593</td>\n",
       "      <td>research study inform effect positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>-1.200618</td>\n",
       "      <td>0.641851</td>\n",
       "      <td>-6.271155</td>\n",
       "      <td>3.869919</td>\n",
       "      <td>power inspire positive create present step happen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    topic  coefficient     p-val  conf_int_low  conf_int_high  \\\n",
       "12     12     9.478323  0.000017      5.202784      13.753863   \n",
       "0       0     8.634836  0.000141      4.217267      13.052406   \n",
       "2       2     9.603615  0.000941      3.937642      15.269588   \n",
       "5       5     7.865123  0.001114      3.156088      12.574159   \n",
       "13     13     7.266651  0.012084      1.600194      12.933108   \n",
       "9       9     7.092919  0.014570      1.409586      12.776252   \n",
       "7       7     4.844886  0.024035      0.640038       9.049734   \n",
       "8       8     4.369447  0.057556     -0.140768       8.879662   \n",
       "1       1     4.272432  0.103782     -0.878772       9.423636   \n",
       "4       4     4.437552  0.131768     -1.338704      10.213807   \n",
       "14     14     4.968919  0.166430     -2.077314      12.015153   \n",
       "11     11     4.274387  0.199766     -2.268084      10.816857   \n",
       "10     10     4.732553  0.209862     -2.674839      12.139944   \n",
       "3       3     2.282184  0.448573     -3.632224       8.196593   \n",
       "6       6    -1.200618  0.641851     -6.271155       3.869919   \n",
       "\n",
       "                                            top_words  \n",
       "12                        success business job create  \n",
       "0     human problem present reason fact effect happen  \n",
       "2                                               women  \n",
       "5                happy positive reason present happen  \n",
       "13                           goal step success create  \n",
       "9                        emotion step effect positive  \n",
       "7     advice step job inform problem inspire business  \n",
       "8                                story inspire happen  \n",
       "1                                relationship problem  \n",
       "4      question ask job create inform business happen  \n",
       "14                          listen present ask advice  \n",
       "11                   habit step effect problem inform  \n",
       "10                                       brain inform  \n",
       "3               research study inform effect positive  \n",
       "6   power inspire positive create present step happen  "
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import top words from topic model and merge with output of linear regression model\n",
    "df_top_words = pd.read_csv('../data/books_25_pages_author_info_description_genres_topics_top_words.csv',skipinitialspace=True)\n",
    "df_top_words = df_top_words.rename(columns = lambda x: x.strip())\n",
    "df_coeff_topics = df_coeff.merge(df_top_words)\n",
    "df_coeff_topics.to_csv('../data/books_25_pages_author_info_description_genres_topics_top_words_ols_coeff.csv',index=False)\n",
    "df_coeff_topics.sort_values(by=['p-val'],ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' think fast slow highli anticip think fast slow kahneman take us groundbreak tour mind explain two system drive way think system fast intuit emot system slower delib logic kahneman expo extraordinari capabilitiesâ€”and also fault biasesâ€”of fast think reveal perva influenc intuit impress thought behavior impact loss aver overconfid corpor strategi difficulti predict make us happi futur challeng properli frame risk work home profound effect cognit bia everyth play stock market plan next vacationâ€”each understood know two system work togeth shape judgment deci engag  live conver think kahneman reveal trust intuit tap benefit slow think offer practic enlighten insight choic made busi person livesâ€”and use differ techniqu guard mental glitch often get us troubl think fast slow transform way think think'"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_1 = 'Thinking, Fast and Slow'\n",
    "description_1 = 'In the highly anticipated Thinking, Fast and Slow, Kahneman takes us on a groundbreaking tour of the mind and explains the two systems that drive the way we think. System 1 is fast, intuitive, and emotional; System 2 is slower, more deliberative, and more logical. Kahneman exposes the extraordinary capabilitiesâ€”and also the faults and biasesâ€”of fast thinking, and reveals the pervasive influence of intuitive impressions on our thoughts and behavior. The impact of loss aversion and overconfidence on corporate strategies, the difficulties of predicting what will make us happy in the future, the challenges of properly framing risks at work and at home, the profound effect of cognitive biases on everything from playing the stock market to planning the next vacationâ€”each of these can be understood only by knowing how the two systems work together to shape our judgments and decisions.Engaging the reader in a lively conversation about how we think, Kahneman reveals where we can and cannot trust our intuitions and how we can tap into the benefits of slow thinking. He offers practical and enlightening insights into how choices are made in both our business and our personal livesâ€”and how we can use different techniques to guard against the mental glitches that often get us into trouble. Thinking, Fast and Slow will transform the way you think about thinking'\n",
    "# keywords_1 = 'nonfiction, psychology, science, business, economics, self help, philosofy, audiobook'\n",
    "# title_1 = 'The Life-Changing Magic of Tidying Up: The Japanese Art of Decluttering and Organizing'\n",
    "# description_1 = 'Despite constant efforts to declutter your home, do papers still accumulate like snowdrifts and clothes pile up like a tangled mess of noodles? Japanese cleaning consultant Marie Kondo takes tidying to a whole new level, promising that if you properly simplify and organize your home once, youll never have to do it again. Most methods advocate a room-by-room or little-by-little approach, which doom you to pick away at your piles of stuff forever. The KonMari Method, with its revolutionary category-by-category system, leads to lasting results. In fact, none of Kondos clients have lapsed (and she still has a three-month waiting list) With detailed guidance for determining which items in your house spark joy (and which dont), this international best seller featuring Tokyos newest lifestyle phenomenon will help you clear your clutter and enjoy the unique magic of a tidy home - and the calm, motivated mindset it can inspire'\n",
    "# keywords_1 = ''\n",
    "# title_1 = 'The Power of Now: A Guide to Spiritual Enlightenment'\n",
    "# description_1 = 'Eckhart Tolles message is simple: living in the now is the truest path to happiness and enlightenment. And while this message may not seem stunningly original or fresh, Tolles clear writing, supportive voice and enthusiasm make this an excellent manual for anyone whos ever wondered what exactly living in the now means. Foremost, Tolle is a world-class teacher, able to explain complicated concepts in concrete language. More importantly, within a chapter of reading this book, readers are already holding the world in a different container--more conscious of how thoughts and emotions get in the way of their ability to live in genuine peace and happiness. Tolle packs a lot of information and inspirational ideas into The Power of Now. (Topics include the source of Chi, enlightened relationships, creative use of the mind, impermanence and the cycle of life.) Thankfully, hes added markers that symbolise break time. This is when readers should close the book and mull over what they just read. As a result, The Power of Now reads like the highly acclaimed A Course in Miracles--a spiritual guidebook that has the potential to inspire just as many study groups and change just as many lives for the better. --Gail Hudson'\n",
    "# keywords_1 = ''\n",
    "# title_1 = ''\n",
    "# description_1 = ''\n",
    "# keywords_1 = 'self help, autism, motivational, money'\n",
    "\n",
    "input_text = title_1+' '+description_1 #+ ' ' + keywords_1\n",
    "processed_input_text = preprocess(input_text)\n",
    "processed_input_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_0</th>\n",
       "      <th>topic_1</th>\n",
       "      <th>topic_2</th>\n",
       "      <th>topic_3</th>\n",
       "      <th>topic_4</th>\n",
       "      <th>topic_5</th>\n",
       "      <th>topic_6</th>\n",
       "      <th>topic_7</th>\n",
       "      <th>topic_8</th>\n",
       "      <th>topic_9</th>\n",
       "      <th>topic_10</th>\n",
       "      <th>topic_11</th>\n",
       "      <th>topic_12</th>\n",
       "      <th>topic_13</th>\n",
       "      <th>topic_14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.006674</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012627</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.163663</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.176229</td>\n",
       "      <td>0.003189</td>\n",
       "      <td>0.006662</td>\n",
       "      <td>0.132984</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    topic_0  topic_1  topic_2   topic_3  topic_4   topic_5  topic_6  topic_7  \\\n",
       "0  0.006674      0.0      0.0  0.012627      0.0  0.163663      0.0      0.0   \n",
       "\n",
       "   topic_8   topic_9  topic_10  topic_11  topic_12  topic_13  topic_14  \n",
       "0      0.0  0.176229  0.003189  0.006662  0.132984       0.0       0.0  "
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform text to features for linear regression\n",
    "num_topics = 15\n",
    "X_tfidf = tfidf_model.transform([processed_input_text])\n",
    "X_nmf = nmf_model.transform(X_tfidf)\n",
    "df_x_nmf = pd.DataFrame(X_nmf,columns = ['topic_'+str(i) for i in range(0,num_topics)]) \n",
    "df_x_nmf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.006674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.012627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.163663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.176229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.003189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0.006662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.132984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    topic  probability\n",
       "0       0     0.006674\n",
       "1       1     0.000000\n",
       "2       2     0.000000\n",
       "3       3     0.012627\n",
       "4       4     0.000000\n",
       "5       5     0.163663\n",
       "6       6     0.000000\n",
       "7       7     0.000000\n",
       "8       8     0.000000\n",
       "9       9     0.176229\n",
       "10     10     0.003189\n",
       "11     11     0.006662\n",
       "12     12     0.132984\n",
       "13     13     0.000000\n",
       "14     14     0.000000"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert into useful dataframe\n",
    "df_x_nmf_tp = df_x_nmf.transpose().reset_index()\n",
    "df_x_nmf_tp = df_x_nmf_tp.rename(columns={'index':'topic',0:'probability'})\n",
    "df_x_nmf_tp['topic'] = list(range(0,len(df_x_nmf_tp['topic'].values)))\n",
    "df_x_nmf_tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.163663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.176229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.132984</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    topic  probability\n",
       "5       5     0.163663\n",
       "9       9     0.176229\n",
       "12     12     0.132984"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# probability cutoff for topic model\n",
    "cutoff_prob = 0.15\n",
    "topics_list = df_x_nmf_tp[df_x_nmf_tp['probability'] > cutoff_prob]['topic'].values\n",
    "df_x_nmf_tp[df_x_nmf_tp['probability'] > cutoff_prob]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>coefficient</th>\n",
       "      <th>p-val</th>\n",
       "      <th>conf_int_low</th>\n",
       "      <th>conf_int_high</th>\n",
       "      <th>top_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>7.865123</td>\n",
       "      <td>0.001114</td>\n",
       "      <td>3.156088</td>\n",
       "      <td>12.574159</td>\n",
       "      <td>happy positive reason present happen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>7.092919</td>\n",
       "      <td>0.014570</td>\n",
       "      <td>1.409586</td>\n",
       "      <td>12.776252</td>\n",
       "      <td>emotion step effect positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>9.478323</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>5.202784</td>\n",
       "      <td>13.753863</td>\n",
       "      <td>success business job create</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    topic  coefficient     p-val  conf_int_low  conf_int_high  \\\n",
       "5       5     7.865123  0.001114      3.156088      12.574159   \n",
       "9       9     7.092919  0.014570      1.409586      12.776252   \n",
       "12     12     9.478323  0.000017      5.202784      13.753863   \n",
       "\n",
       "                               top_words  \n",
       "5   happy positive reason present happen  \n",
       "9           emotion step effect positive  \n",
       "12           success business job create  "
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#words of topics that have probability > cutoff_prob\n",
    "df_topics_high_prob = df_coeff_topics[df_coeff_topics['topic'].isin(topics_list)]\n",
    "df_topics_high_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>coefficient</th>\n",
       "      <th>p-val</th>\n",
       "      <th>conf_int_low</th>\n",
       "      <th>conf_int_high</th>\n",
       "      <th>top_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>7.865123</td>\n",
       "      <td>0.001114</td>\n",
       "      <td>3.156088</td>\n",
       "      <td>12.574159</td>\n",
       "      <td>happy positive reason present happen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>7.092919</td>\n",
       "      <td>0.014570</td>\n",
       "      <td>1.409586</td>\n",
       "      <td>12.776252</td>\n",
       "      <td>emotion step effect positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>9.478323</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>5.202784</td>\n",
       "      <td>13.753863</td>\n",
       "      <td>success business job create</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    topic  coefficient     p-val  conf_int_low  conf_int_high  \\\n",
       "5       5     7.865123  0.001114      3.156088      12.574159   \n",
       "9       9     7.092919  0.014570      1.409586      12.776252   \n",
       "12     12     9.478323  0.000017      5.202784      13.753863   \n",
       "\n",
       "                               top_words  \n",
       "5   happy positive reason present happen  \n",
       "9           emotion step effect positive  \n",
       "12           success business job create  "
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# output top words\n",
    "df_topics_high_prob[df_topics_high_prob['p-val']<0.05]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
